{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import diffusers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import LMSDiscreteScheduler, StableDiffusionPipeline\n",
    "from PIL import Image\n",
    "from skimage.exposure import match_histograms\n",
    "from torch import autocast\n",
    "from torchvision import transforms as tfms\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from img2img import StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STABLE_DIFFUSION_MODEL_PATH = Path.home() / \"Desktop/stable-diffusion-v1-4\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'trained_betas'} was not found in config. Values will be initialized to default values.\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionImg2ImgPipeline {\n",
       "  \"_class_name\": \"StableDiffusionImg2ImgPipeline\",\n",
       "  \"_diffusers_version\": \"0.3.0\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"LMSDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the txt_to_img pipeline\n",
    "txt_to_img = StableDiffusionPipeline.from_pretrained(\n",
    "    str(STABLE_DIFFUSION_MODEL_PATH), revision=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "# Turn off safety_checker to avoid false positives\n",
    "txt_to_img.safety_checker = lambda images, **kwargs: (images, False)\n",
    "# txt_to_img.enable_attention_slicing()  # use less vram\n",
    "txt_to_img = txt_to_img.to(device)\n",
    "# Load the img2img pipeline, using the models\n",
    "# from the txt_to_img pipeline, to not waste vram.\n",
    "im2im = StableDiffusionImg2ImgPipeline(\n",
    "    vae=txt_to_img.vae,\n",
    "    text_encoder=txt_to_img.text_encoder,\n",
    "    tokenizer=txt_to_img.tokenizer,\n",
    "    unet=txt_to_img.unet,\n",
    "    scheduler=LMSDiscreteScheduler(\n",
    "        beta_start=0.00085,\n",
    "        beta_end=0.012,\n",
    "        beta_schedule=\"scaled_linear\",\n",
    "        num_train_timesteps=1000,\n",
    "    ),\n",
    ")\n",
    "# im2im.enable_attention_slicing()\n",
    "im2im.progress_bar = lambda iterable: iterable  # turn off progress bar\n",
    "im2im.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "\n",
    "def timestamp():\n",
    "    return time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "def maintain_colors(prev_img, color_match_sample, mode):\n",
    "    # source: https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb#scrollTo=2g-f7cQmf2Nt\n",
    "    if mode == \"Match Frame 0 RGB\":\n",
    "        return match_histograms(prev_img, color_match_sample, multichannel=True)\n",
    "    elif mode == \"Match Frame 0 HSV\":\n",
    "        prev_img_hsv = cv2.cvtColor(prev_img, cv2.COLOR_RGB2HSV)\n",
    "        color_match_hsv = cv2.cvtColor(color_match_sample, cv2.COLOR_RGB2HSV)\n",
    "        matched_hsv = match_histograms(prev_img_hsv, color_match_hsv, multichannel=True)\n",
    "        return cv2.cvtColor(matched_hsv, cv2.COLOR_HSV2RGB)\n",
    "    else:  # Match Frame 0 LAB\n",
    "        prev_img_lab = cv2.cvtColor(prev_img, cv2.COLOR_RGB2LAB)\n",
    "        color_match_lab = cv2.cvtColor(color_match_sample, cv2.COLOR_RGB2LAB)\n",
    "        matched_lab = match_histograms(prev_img_lab, color_match_lab, multichannel=True)\n",
    "        return cv2.cvtColor(matched_lab, cv2.COLOR_LAB2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook_path.resolve() = PosixPath('/home/sid/Documents/stable-diffusion-im2im/main.ipynb')\n",
      "OUTPUT_DIR.resolve() = PosixPath('/home/sid/Documents/stable-diffusion-im2im/images/20221002-125521')\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = Path(f\"images/{timestamp()}\")\n",
    "PROMPT_A = \"A photo of a bowl of fruit\"\n",
    "PROMPT_B = \"A photo of an acrobat\"\n",
    "GUIDANCE_SCALE = 7.5\n",
    "IMG2IMG_STRENGTH = 0.5\n",
    "NUM_IMG2IMG_STEPS = 100\n",
    "SEED = 0\n",
    "WIDTH = 512\n",
    "HEIGHT = 512\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "# Use same random seed for everything\n",
    "generator = torch.Generator(\"cuda\").manual_seed(SEED)\n",
    "# To know where things were\n",
    "notebook_path = Path(__vsc_ipynb_file__)  # vscode only\n",
    "print(f\"{notebook_path.resolve() = }\")\n",
    "print(f\"{OUTPUT_DIR.resolve() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('images/20221002-125521/main_20221002-125523.ipynb')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save a copy of this nb in OUTPUT_DIR, for reproducibility\n",
    "shutil.copy(\n",
    "    src=notebook_path, dst=OUTPUT_DIR / f\"{notebook_path.stem}_{timestamp()}.ipynb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:10<00:00,  4.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the initial image\n",
    "with autocast(\"cuda\"), torch.no_grad():\n",
    "    init_image = txt_to_img(\n",
    "        [PROMPT_A], width=WIDTH, height=HEIGHT, generator=generator\n",
    "    )[\"sample\"][0]\n",
    "init_image.save(OUTPUT_DIR / f\"{PROMPT_A}_{PROMPT_B}_{0:04d}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]/tmp/ipykernel_52008/570955215.py:11: FutureWarning: `multichannel` is a deprecated argument name for `match_histograms`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  return match_histograms(prev_img, color_match_sample, multichannel=True)\n",
      "100%|██████████| 99/99 [08:22<00:00,  5.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate the rest of the images\n",
    "image = init_image\n",
    "for i in tqdm(range(1, NUM_IMG2IMG_STEPS)):\n",
    "    # Try to prevent colours from going red\n",
    "    image = maintain_colors(np.array(image), np.array(init_image), \"Match Frame 0 RGB\")\n",
    "    image = Image.fromarray(image)\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(i)\n",
    "    with autocast(\"cuda\"), torch.no_grad():\n",
    "        image = im2im(\n",
    "            PROMPT_B,\n",
    "            image,\n",
    "            strength=IMG2IMG_STRENGTH,\n",
    "            guidance_scale=GUIDANCE_SCALE,\n",
    "            generator=generator,\n",
    "        )[\"sample\"][0]\n",
    "    image.save(OUTPUT_DIR / f\"{PROMPT_A}_{PROMPT_B}_{i:04d}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 10.4.0 (conda-forge gcc 10.4.0-16)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1664281150702/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1664281150702/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1664281150702/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1664281150702/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1664281150702/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-avresample --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1664281150702/_build_env/bin/pkg-config\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from 'images/20221002-125521/*.jpg':\n",
      "  Duration: 00:00:01.67, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 512x512 [SAR 1:1 DAR 1:1], 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x55f2476e0500] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0m264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=16 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'images/20221002-125521/movie.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt470bg/unknown/unknown, progressive), 512x512 [SAR 1:1 DAR 1:1], q=2-31, 60 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  100 fps=0.0 q=-1.0 Lsize=     699kB time=00:00:01.61 bitrate=3542.1kbits/s speed=2.68x    \n",
      "video:697kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.290293%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mframe I:1     Avg QP:32.93  size: 17867\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mframe P:25    Avg QP:30.13  size:  8535\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mframe B:74    Avg QP:30.87  size:  6511\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mconsecutive B-frames:  1.0%  0.0%  3.0% 96.0%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mmb I  I16..4:  1.4% 82.9% 15.7%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mmb P  I16..4: 32.5% 41.1%  3.8%  P16..4: 13.3%  7.2%  2.0%  0.0%  0.0%    skip: 0.2%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mmb B  I16..4: 11.6% 16.3%  1.1%  B16..8: 33.8% 12.3%  2.3%  direct:16.5%  skip: 6.2%  L0:45.6% L1:43.7% BI:10.6%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0m8x8 transform intra:55.5% inter:84.8%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mcoded y,uvDC,uvAC intra: 36.1% 74.0% 34.7% inter: 33.8% 84.9% 13.0%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mi16 v,h,dc,p: 17% 12%  4% 67%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 16% 21%  6%  8%  9%  7%  8%  5%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 13% 20%  7%  9%  9%  7%  8%  4%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mi8c dc,h,v,p: 46% 18% 21% 16%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mWeighted P-Frames: Y:24.0% UV:24.0%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mref P L0: 40.3% 12.4% 27.1% 17.3%  2.9%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mref B L0: 77.6% 17.8%  4.6%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mref B L1: 89.8% 10.2%\n",
      "\u001b[1;36m[libx264 @ 0x55f24736f180] \u001b[0mkb/s:3422.75\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -framerate 60 -pattern_type glob -i \"{OUTPUT_DIR}/*.jpg\"  \\\n",
    "    -c:v libx264 -pix_fmt yuv420p -vf trim=0:30 \"{OUTPUT_DIR}/movie.mp4\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('stable-diffusion-im2im')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cea3af3ea9aced30a5c72c792fbd026032c096800e9cc9471dd580bb4e3cffca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
